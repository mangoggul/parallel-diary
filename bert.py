import torch
from transformers import AutoModel, AutoTokenizer, XLNetTokenizer

# ì´ ë°©ë²•ì´ BertTokenizerë¥¼ ê°•ì œë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ì•ˆì •ì ì…ë‹ˆë‹¤.
tokenizer = XLNetTokenizer.from_pretrained("skt/kobert-base-v1")

# 2. ëª¨ë¸ì€ AutoModelë¡œ ë¡œë“œ (ì´ê²ƒì€ ë³´í†µ ë¬¸ì œê°€ ì—†ìŒ)
model = AutoModel.from_pretrained("skt/kobert-base-v1")

# 1. ì„ì˜ ì¼ê¸° ë°ì´í„° ìƒì„±
diary_data = [
    "2025ë…„ 11ì›” 20ì¼ ëª©ìš”ì¼. ë‚ ì”¨ê°€ ë§‘ì•„ì„œ ê¸°ë¶„ì´ ì •ë§ ì¢‹ì•˜ë‹¤.",
    "ì•„ì¹¨ì— ë”°ëœ»í•œ ì»¤í”¼ í•œ ì”ì„ ë§ˆì‹œë©° ì—¬ìœ ë¡œìš´ ì‹œê°„ì„ ë³´ëƒˆë‹¤.",
    "ì˜¤í›„ì—ëŠ” ì¹œêµ¬ë¥¼ ë§Œë‚˜ì„œ ì¬ë¯¸ìˆëŠ” ì˜í™”ë¥¼ ë´¤ë‹¤. ë‚´ìš©ì€ ì¡°ê¸ˆ ìŠ¬íì§€ë§Œ ì¢‹ì•˜ë‹¤.",
    "ì €ë…ì—ëŠ” ì˜¤ëœë§Œì— ê°€ì¡±ë“¤ê³¼ í•¨ê»˜ ë§›ìˆëŠ” ì €ë… ì‹ì‚¬ë¥¼ í–ˆë‹¤. í–‰ë³µí•œ í•˜ë£¨ì˜€ë‹¤.",
    "ë‚´ì¼ì€ ë” ì‹ ë‚˜ëŠ” ì¼ì´ ìƒê¸¸ ê²ƒ ê°™ì€ ì˜ˆê°ì´ ë“ ë‹¤."
]

print("## ğŸ““ ìƒì„±ëœ ì¼ê¸° ë°ì´í„°")
for idx, text in enumerate(diary_data):
    print(f"[{idx+1}] {text}")

print("\n" + "="*50 + "\n")

print("## âœ¨ XLNetTokenizerë¥¼ ì´ìš©í•œ í† í°í™” (Subword ë¶„ì„)")

# 3. ê° ì¼ê¸° ë¬¸ì¥ì— ëŒ€í•´ í† í°í™” ë° ë¶„ì„ ìˆ˜í–‰
for i, sentence in enumerate(diary_data):
    # íŠ¹ìˆ˜ í† í°([CLS], [SEP])ì„ í¬í•¨í•˜ì—¬ ì¸ì½”ë”©
    tokenized_output = tokenizer.encode_plus(
        sentence,
        add_special_tokens=True, # [CLS]ì™€ [SEP] ì¶”ê°€
        return_tensors='pt'       # PyTorch í…ì„œë¡œ ë°˜í™˜
    )

    if 'token_type_ids' in tokenized_output:
        del tokenized_output['token_type_ids']

    # í† í° IDë¥¼ ì‹¤ì œ í…ìŠ¤íŠ¸ í† í°ìœ¼ë¡œ ë³€í™˜
    tokens = tokenizer.convert_ids_to_tokens(tokenized_output['input_ids'][0])

    print(f"\n--- [ì¼ê¸° {i+1}] ì›ë³¸: {sentence} ---")
    print(f"ğŸ” í† í° ì‹œí€€ìŠ¤: {tokens}")
    print(f"ğŸ“ í† í° ê°œìˆ˜ (íŠ¹ìˆ˜ í† í° í¬í•¨): {len(tokens)}")

    # 4. BERT ì„ë² ë”© ë²¡í„° ìƒì„±
    with torch.no_grad():
        outputs = model(**tokenized_output)
        last_hidden_states = outputs.last_hidden_state

    # ì„ë² ë”© ë²¡í„°ì˜ í¬ê¸° í™•ì¸ (í† í° ê°œìˆ˜ x ì„ë² ë”© ì°¨ì›)
    print(f"ğŸ“Š ì„ë² ë”© ë²¡í„° í¬ê¸°: {last_hidden_states.shape} (í† í°ìˆ˜, ì„ë² ë”©_ì°¨ì›)")