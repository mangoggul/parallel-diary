import torch
from transformers import AutoModel, XLNetTokenizer
import torch.nn.functional as F
import random
import datetime

# 1. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ
print("KoBERT í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ ì¤‘...")
tokenizer = XLNetTokenizer.from_pretrained("skt/kobert-base-v1")
model = AutoModel.from_pretrained("skt/kobert-base-v1")
print("ë¡œë“œ ì™„ë£Œ.")

# 2. ì„ì˜ ì¼ê¸° ë°ì´í„° 100ê°œ ìƒì„± í•¨ìˆ˜
def generate_random_diary_entry(entry_id):
    templates = [
        f"{entry_id}ë²ˆ ì¼ê¸°. ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ [ë‚ ì”¨]í•´ì„œ ê¸°ë¶„ì´ [ê¸°ë¶„] ì¢‹ì•˜ë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ì‹œê°„]ì— [í™œë™]ì„ í•˜ë©° [ëŠë‚Œ] ì‹œê°„ì„ ë³´ëƒˆë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ì¥ì†Œ]ì—ì„œ [ëˆ„êµ¬]ë¥¼ ë§Œë‚˜ [ê²½í—˜]í–ˆë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ì €ë…]ì—ëŠ” [ëŒ€ìƒ]ê³¼ í•¨ê»˜ [í–‰ë™]í–ˆë‹¤. [ê²°ë¡ ].",
        f"{entry_id}ë²ˆ ì¼ê¸°. ë‚´ì¼ì€ [ë¯¸ë˜_ê¸°ëŒ€] ì¼ì´ ìƒê¸¸ ê²ƒ ê°™ì€ ì˜ˆê°ì´ ë“ ë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ì˜¤ëŠ˜ì˜_ìƒê°]ì— ëŒ€í•´ ê¹Šì´ ìƒê°í•´ë³´ëŠ” ì‹œê°„ì´ì—ˆë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. ì˜¤ëœë§Œì— [ë¬´ì—‡]ì„ í•´ì„œ [ê°ì •]ì„ ëŠê¼ˆë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ì£¼ë§]ì—ëŠ” [ê³„íš]ì„ ì„¸ì›Œë³¼ ìƒê°ì´ë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ë‚ ì§œ]ì˜ ì¼ê¸°. [ì‚¬ê±´]ì´ ìˆì–´ì„œ [ë°˜ì‘]í–ˆë‹¤.",
        f"{entry_id}ë²ˆ ì¼ê¸°. [ê²½í—˜_êµ¬ì²´í™”]í•˜ëŠ” í•˜ë£¨ì˜€ë‹¤. [ì´í‰]."
    ]

    weather = ["ë§‘", "íë¦¼", "ë¹„", "êµ¬ë¦„", "ëˆˆ"]
    mood = ["ì •ë§", "ë§¤ìš°", "ì¡°ê¸ˆ", "ê½¤", "ê·¸ëƒ¥"]
    time = ["ì•„ì¹¨", "ì˜¤í›„", "ì €ë…", "ë°¤ëŠ¦ê²Œ", "ì ì‹¬ì‹œê°„"]
    activity = ["ë”°ëœ»í•œ ì»¤í”¼ í•œ ì”", "ì‚°ì±…", "ì±… ì½ê¸°", "ìŒì•… ê°ìƒ", "ìš´ë™"]
    feeling = ["ì—¬ìœ ë¡œìš´", "í‰í™”ë¡œìš´", "ì§€ë£¨í•œ", "ì¦ê±°ìš´", "í˜ë“ "]
    place = ["ì§‘ ê·¼ì²˜ ì¹´í˜", "ê³µì›", "ë„ì„œê´€", "ì¹œêµ¬ ì§‘", "íšŒì‚¬ ì•"]
    who = ["ì¹œêµ¬", "ê°€ì¡±", "ë™ë£Œ", "í˜¼ì", "ì—°ì¸"]
    experience = ["ì¬ë¯¸ìˆëŠ” ì˜í™”ë¥¼ ë´¤", "ë§›ìˆëŠ” ì‹ì‚¬ë¥¼ í–ˆ", "ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ´", "ì‡¼í•‘ì„ í–ˆ", "ìƒˆë¡œìš´ ê²ƒì„ ë°°ì› "]
    evening_activities = ["ë§›ìˆëŠ” ì €ë… ì‹ì‚¬", "ëŠ¦ì ", "ë“œë¼ë§ˆ ì‹œì²­", "ì²­ì†Œ", "ê²Œì„"]
    target = ["ê°€ì¡±ë“¤", "ì¹œêµ¬ë“¤", "ì• ì¸", "ë‚˜ ìì‹ ", "ë°˜ë ¤ë™ë¬¼"]
    action = ["ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ëƒˆ", "íœ´ì‹ì„ ì·¨í–ˆ", "ì˜ê²¬ì„ êµí™˜í–ˆ", "ì¶”ì–µì„ ë§Œë“¤ì—ˆ", "í•˜ë£¨ë¥¼ ì •ë¦¬í–ˆ"]
    conclusion = ["í–‰ë³µí•œ í•˜ë£¨ì˜€ë‹¤", "í”¼ê³¤í–ˆì§€ë§Œ ë³´ëŒ ìˆì—ˆë‹¤", "ìƒê°ì´ ë§ì•„ì¡Œë‹¤", "ë‚´ì¼ì„ ê¸°ì•½í–ˆë‹¤", "ì•„ì‰¬ì›€ì´ ë‚¨ëŠ”ë‹¤"]
    future_expectation = ["ì‹ ë‚˜ëŠ”", "í¥ë¯¸ë¡œìš´", "ìƒˆë¡œìš´", "íŠ¹ë³„í•œ", "ì–´ë ¤ìš´"]
    todays_thought = ["ì¸ìƒì˜ ì˜ë¯¸", "ì§ì—…ì˜ ê°€ì¹˜", "ì¸ê°„ê´€ê³„", "ë¯¸ë˜ ê³„íš", "ê³¼ê±°ì˜ ì¶”ì–µ"]
    what = ["ìƒˆë¡œìš´ ìŒì‹", "ì˜¤ë˜ëœ ì˜í™”", "ì¹œêµ¬ì™€ì˜ í†µí™”", "ì·¨ë¯¸ í™œë™", "ì—¬í–‰ ê³„íš"]
    emotion = ["ì¦ê±°ì›€", "í¸ì•ˆí•¨", "ì•„ì‰¬ì›€", "ê¸°ëŒ€ê°", "ë§Œì¡±ê°"]
    weekend_plan = ["ì—¬í–‰ ì¤€ë¹„", "ë°€ë¦° ì  ìê¸°", "ìš´ë™í•˜ê¸°", "ì¹œêµ¬ ë§Œë‚˜ê¸°", "ì˜í™” ë³´ê¸°"]
    event = ["ì˜ˆìƒì¹˜ ëª»í•œ ì†Œì‹", "ì‘ì€ ì„±ê³µ", "ì–´ë ¤ìš´ ë¬¸ì œ", "ìƒˆë¡œìš´ ë§Œë‚¨", "ì˜¤ë˜ëœ ì¹œêµ¬ì™€ì˜ ì¬íšŒ"]
    response = ["ë†€ëë‹¤", "ê¸°ë»¤ë‹¤", "ê³ ë¯¼ì— ë¹ ì¡Œë‹¤", "ì¦ê±°ì› ë‹¤", "ë°˜ê°€ì› ë‹¤"]
    detailed_experience = ["ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë– ì˜¬ë¦¬", "ì˜ˆìƒì¹˜ ëª»í•œ í–‰ìš´ì´ ì°¾ì•„ì˜¤", "ì†Œì†Œí•œ ì¼ìƒì—ì„œ í–‰ë³µì„ ì°¾", "í•˜ë£¨ ì¢…ì¼ ìƒê°ì— ì ê¸°", "ì¦ê±°ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„"]
    summary = ["ì¦ê±°ìš´ í•˜ë£¨ì˜€ë‹¤", "ìƒê°ì´ ê¹Šì–´ì§„ ë‚ ì´ì—ˆë‹¤", "í‰ë²”í–ˆì§€ë§Œ ì†Œì¤‘í•œ í•˜ë£¨ì˜€ë‹¤", "ë‹¤ìŒì´ ê¸°ëŒ€ë˜ëŠ” í•˜ë£¨ì˜€ë‹¤", "í”¼ê³¤í–ˆì§€ë§Œ ì•Œì°¬ í•˜ë£¨ì˜€ë‹¤"]


    replacements = {
        "[ë‚ ì”¨]": random.choice(weather),
        "[ê¸°ë¶„]": random.choice(mood),
        "[ì‹œê°„]": random.choice(time),
        "[í™œë™]": random.choice(activity),
        "[ëŠë‚Œ]": random.choice(feeling),
        "[ì¥ì†Œ]": random.choice(place),
        "[ëˆ„êµ¬]": random.choice(who),
        "[ê²½í—˜]": random.choice(experience),
        "[ì €ë…]": random.choice(evening_activities),
        "[ëŒ€ìƒ]": random.choice(target),
        "[í–‰ë™]": random.choice(action),
        "[ê²°ë¡ ]": random.choice(conclusion),
        "[ë¯¸ë˜_ê¸°ëŒ€]": random.choice(future_expectation),
        "[ì˜¤ëŠ˜ì˜_ìƒê°]": random.choice(todays_thought),
        "[ë¬´ì—‡]": random.choice(what),
        "[ê°ì •]": random.choice(emotion),
        "[ì£¼ë§]": random.choice(weekend_plan),
        "[ì‚¬ê±´]": random.choice(event),
        "[ë°˜ì‘]": random.choice(response),
        "[ê²½í—˜_êµ¬ì²´í™”]": random.choice(detailed_experience),
        "[ì´í‰]": random.choice(summary),
        "[ë‚ ì§œ]": (datetime.date(2025, 1, 1) + datetime.timedelta(days=random.randint(0, 364))).strftime("%Yë…„ %mì›” %dì¼")
    }

    template = random.choice(templates)
    for key, value in replacements.items():
        template = template.replace(key, value)
    return template

# 100ê°œì˜ ì„ì˜ ì¼ê¸° ë°ì´í„° ìƒì„±
diary_data_100 = [generate_random_diary_entry(i+1) for i in range(100)]

print("## ğŸ““ ìƒì„±ëœ 100ê°œì˜ ì¼ê¸° ë°ì´í„° (ì¼ë¶€ë§Œ ì¶œë ¥)")
for idx, text in enumerate(diary_data_100[:5]): # ì²˜ìŒ 5ê°œë§Œ ì˜ˆì‹œë¡œ ì¶œë ¥
    print(f"[{idx+1}] {text}")
if len(diary_data_100) > 5:
    print(f"... (ì´ {len(diary_data_100)}ê°œ ë¬¸ì¥)")

print("\n" + "="*50 + "\n")

print("## âœ¨ 100ê°œ ë¬¸ì¥ì˜ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")

# ë¬¸ì¥ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def get_sentence_embedding(sentence, tokenizer, model):
    tokenized_output = tokenizer.encode_plus(
        sentence,
        add_special_tokens=True,
        return_tensors='pt'
    )
    
    # KoBERT í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°: token_type_ids ì œê±°
    if 'token_type_ids' in tokenized_output:
        del tokenized_output['token_type_ids']

    with torch.no_grad():
        outputs = model(**tokenized_output)
        last_hidden_states = outputs.last_hidden_state
        
    # [CLS] í† í°ì˜ ì„ë² ë”©ë§Œ ì¶”ì¶œ (ë¬¸ì¥ ì„ë² ë”©)
    return last_hidden_states[:, 0, :].squeeze(0)

# 2. 100ê°œ ë¬¸ì¥ ëª¨ë‘ì˜ ì„ë² ë”© ë²¡í„° ìƒì„±
embeddings = []
for i, sentence in enumerate(diary_data_100):
    embedding = get_sentence_embedding(sentence, tokenizer, model)
    embeddings.append(embedding)
    if (i + 1) % 10 == 0:
        print(f"  - {i+1}/{len(diary_data_100)} ë¬¸ì¥ ì„ë² ë”© ì™„ë£Œ.")

# PyTorch í…ì„œë¡œ ë³€í™˜: [100, 768]
embedding_matrix = torch.stack(embeddings) 
print(f"ì´ {embedding_matrix.shape[0]}ê°œ ë¬¸ì¥ì˜ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì™„ë£Œ: {embedding_matrix.shape}")

print("\n" + "="*50 + "\n")
print("## âœ¨ ëª¨ë“  ìŒì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ì¤‘...")

# 3. ëª¨ë“  ìŒì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
# ë²¡í„° ì •ê·œí™”: ê° ì„ë² ë”© ë²¡í„°ë¥¼ ë‹¨ìœ„ ê¸¸ì´(í¬ê¸° 1)ë¡œ ë§Œë“­ë‹ˆë‹¤.
normalized_embeddings = F.normalize(embedding_matrix, p=2, dim=1)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°: í–‰ë ¬ * í–‰ë ¬ì˜ ì „ì¹˜ (A * A_T)
# ê²°ê³¼ëŠ” [100x100] í–‰ë ¬ì´ ë©ë‹ˆë‹¤.
similarity_matrix = torch.matmul(normalized_embeddings, normalized_embeddings.transpose(0, 1))

# ê²°ê³¼ ì¶œë ¥ (í–‰ë ¬ì´ ë„ˆë¬´ ì»¤ì„œ ì „ì²´ ì¶œë ¥ì€ ì–´ë µìŠµë‹ˆë‹¤. ì¼ë¶€ë§Œ ì¶œë ¥)
print(f"ì´ {similarity_matrix.shape[0]}x{similarity_matrix.shape[1]} ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± ì™„ë£Œ.")
print("í–‰ë ¬ì˜ (i, j) ì›ì†ŒëŠ” ë¬¸ì¥ iì™€ ë¬¸ì¥ jì˜ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")

print("\n## ğŸ“Š ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ (ì¼ë¶€ ì¶œë ¥: 0~4ë²ˆ ë¬¸ì¥ vs 0~4ë²ˆ ë¬¸ì¥)")
# ì²˜ìŒ 5x5 ë¶€ë¶„ë§Œ ì¶œë ¥í•˜ì—¬ ì˜ˆì‹œë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
similarity_matrix_np = similarity_matrix[:5, :5].cpu().numpy()
formatted_matrix_partial = [[f"{val:.4f}" for val in row] for row in similarity_matrix_np]

header_partial = [""] + [f"Sent {i+1}" for i in range(5)]
row_format_partial = "{:<10}" * (len(header_partial))
print(row_format_partial.format(*header_partial))
print("-" * (10 * len(header_partial)))

for i, row in enumerate(formatted_matrix_partial):
    print(row_format_partial.format(f"Sent {i+1}", *row))

# ëª¨ë“  ë¬¸ì¥ ìŒì˜ í‰ê·  ìœ ì‚¬ë„ (ë‹¨ì¡°ë¡œì›€ ì§€ìˆ˜) ê³„ì‚°
# ëŒ€ê°ì„  (ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„)ì„ ì œì™¸í•œ ê°’ë“¤ì˜ í‰ê· 
# ìƒì‚¼ê° í–‰ë ¬ ë˜ëŠ” í•˜ì‚¼ê° í–‰ë ¬ì˜ ì›ì†Œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
upper_triangle_indices = torch.triu_indices(similarity_matrix.shape[0], similarity_matrix.shape[1], offset=1)
pairwise_similarities = similarity_matrix[upper_triangle_indices[0], upper_triangle_indices[1]]
average_similarity = torch.mean(pairwise_similarities).item()

print("\n" + "="*50)
print(f"âœ… ì´ {len(diary_data_100)}ê°œ ë¬¸ì¥ì— ëŒ€í•œ ëª¨ë“  ìŒì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ.")
print(f"**ì „ì²´ ë¬¸ì¥ ìŒ ê°œìˆ˜:** {len(diary_data_100) * (len(diary_data_100) - 1) // 2}ê°œ")
print(f"**ëª¨ë“  ë¬¸ì¥ ìŒì˜ í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ì˜ë¯¸ì  ë‹¨ì¡°ë¡œì›€ ì§€ìˆ˜):** {average_similarity:.4f}")
print("í‰ê·  ìœ ì‚¬ë„ ê°’ì´ 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¬¸ì¥ë“¤ì´ ì „ë°˜ì ìœ¼ë¡œ ë‹¨ì¡°ë¡­ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.")
print("="*50)